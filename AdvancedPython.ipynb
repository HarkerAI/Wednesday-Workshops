{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Python Workshop\n",
    "========\n",
    "***\n",
    "\n",
    "Welcome!\n",
    "-----\n",
    "\n",
    "This workshop is intended to give you a background in the most commonly-used Python libraries and operations. Here's an outline of the topics we'll cover today:\n",
    "\n",
    "1) NumPy Tutorial:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a) Array Creation  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b) Shape Manipulation  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c) Important Array Operations  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d) Data Retrieval  \n",
    "2) Pandas Tutorial  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a) ```Series``` Creation and Manipulation  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b) ```DataFrame``` Creation and Manipulation  \n",
    "3) Basic Data Retrieval from Files  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a) CSV Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary Libraries\n",
    "-----------------\n",
    "Two of the most-used libraries in Python are ```numpy``` and ```pandas```. They both offer their own more advanced data structures, and they are almost always used in real-world applications. You will find that plain python without any libraries is almost never used.  \n",
    "\n",
    "If you haven't imported libraries in Python before, you can think of it like you're using static classes in Java (e.g. Math). When you import a library ```as``` something, you are telling Python the name by which you will reference the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #if you import numpy as anything other than np, you will be ostracized from the python community\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy Tutorial\n",
    "---\n",
    "NumPy is a widely-used math and scientific library in Python. Most importantly, it gives us a new data structure that allows us to manipulate data much more easily, and it is used extensively in neural networks and other machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Creation\n",
    "The main structure that NumPy gives us is its powerful ```ndarray``` structure. This structure goes far beyond the Python standard structures (which really nobody ever uses), including functionality to reshape multidimensional arrays and higher-level math performance.\n",
    "\n",
    "Let's begin by creating a 1-dimensional array of 10 integers, 0-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.arange(10) #N.B. the function name is \"arange\" not \"arrange\"\n",
    "print(arr)\n",
    "print(type(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, we have created an array of a type other than Python's standard. You can also create NumPy arrays out of standard lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standardArray = [0,1,2,3,4,5,6,7,8,9]\n",
    "print(type(standardArray))\n",
    "numpyArray = np.array(standardArray)\n",
    "print(type(numpyArray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ndarray Shape\n",
    "Now we'll go over what you can do with NumPy arrays. First, we need to define shape. Shape refers to the dimensions of a multidimensional array. For example, let's say I have a 2-D array as follows:\n",
    "\n",
    "\\[\\[a b c d\\]  \n",
    " \\[e f g h\\]\\]\n",
    " \n",
    "We would say that this 2-D array has a shape of (2,4). NumPy allows us to determine the shape of a NumPy array by using the ```shape()``` function, and we can also use the ```reshape()``` function to re-dimension arrays. Let's use these functions to find the initial shape of ```numpyArray``` and reshape it so that it has two rows and five columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Initial array: \" + str(numpyArray) + \"\\n\")\n",
    "print(\"Shape of initial array: \" + str(np.shape(numpyArray)) + \"\\n\")\n",
    "numpyArray = numpyArray.reshape(2,5)\n",
    "print(\"Final array: \")\n",
    "print(str(numpyArray) + \"\\n\")\n",
    "print(\"Shape of final array: \" + str(np.shape(numpyArray)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve some data from this array. Remember that, like in Java, Python goes row, then column. Additionally, Python is generally ***zero-indexed***, meaning that the first element in an array is treated as the \"zeroeth\" element. Thus, to get the value of the element from the second row and third column, we say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(numpyArray[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that we chose to reshape the array to two rows and five columns because 2\\*5 = 10, the number of elements in the array. Let's see what happens when we try to reshape the array to something that doesn't match the number of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpyArray = numpyArray.reshape(2,6)\n",
    "print(numpyArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woops, we get an error! Remember, even if you reshape an array such that the final dimensions can hold more values than necessary, you will get an error.\n",
    "\n",
    "### Other Important Array Operations\n",
    "\n",
    "Now that we have introduced the concept of shape, everything else about arrays in NumPy is pretty straightforward. \n",
    "\n",
    "Most methods for iteration over NumPy arrays are the same as those for standard Python lists. Let's create a new NumPy array of digits 0 to 4 and print them using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basicArray = np.arange(4)\n",
    "for i in basicArray:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One function that is often used is ```zeros()```. This function is very simple: it creates an array filled with zeros given a shape. (There is also another similar function called ```ones()```.) Let's make an 2 x 3 array filled with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exampleArray = np.zeros((2,3))\n",
    "print(exampleArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say I wanted to increment all the values in ```exampleArray``` by 3. We *could* iterate over the array and add 3 to each value, but instead we should take advantage of the fact that NumPy has ***element-wise operations***. This means that if I perform a function on the array, the function is applied to each element, and the shape of the array is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exampleArray = exampleArray + 3\n",
    "print(exampleArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same property applies to other arithmetic operations, including subtraction, multiplication, division, and exponentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exampleArray *= 2\n",
    "print(exampleArray)\n",
    "exampleArray **= 2\n",
    "print(exampleArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sub-Array Data Retrieval**: One interesting feature of Python is the ability to gather sections of data from arrays. For example, let's say I have a single-dimension array of 5 random values between 0 and 10, singleDimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "singleDimension = np.random.rand(5)*10\n",
    "print(singleDimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can retrieve a sub-array of values for indices between 2 and 4 as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(singleDimension[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first index is inclusive and the second is exclusive. You'll see this notation frequently in the future. Another thing to note is that when you want a sub-array that begins at index 0, you can actually just leave the \"0\" out and it'll work fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(singleDimension[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have an understanding of the NumPy library, we can start using the Pandas library, which builds on NumPy constructs. Much like NumPy offers its primary data structure ```ndarray```, Pandas offers two data structures called ```Series``` and ```DataFrame```. You'll find that ```Series``` is much like NumPy's array, and ```DataFrame``` allows you to observe data in a table-like manner. For those of you who have used the R Programming Language, ```DataFrame``` is similar to the R structure of the same name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, ```Series``` is very similar to ```ndarray```. Essentially, a ```Series``` is just a labelled array. You can even create a ```Series``` out of an ```ndarray```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apcsDiagnosticScores = np.random.rand(6)*50 + 10 #We take advantage of element-wise operations to generate random numbers between 10 and 60\n",
    "diagnosticScoreAssignments = pd.Series(apcsDiagnosticScores, index=[\"Alex\", \"Alice\", \"Bob\", \"Katie\", \"Rajesh\", \"Ryan\"])\n",
    "print(diagnosticScoreAssignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier with ```ndarray```s, ```Series``` also support element-wise operations. For example, let's say we wanted to add a 40% curve given the ~~abysmal~~ less-than-expected scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diagnosticScoreAssignmentsWithCurve = diagnosticScoreAssignments + 40\n",
    "print(diagnosticScoreAssignmentsWithCurve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to retrieve data from ```Series```, we use notation similar to arrays: square brackets. You can retrieve data based either on the identifier (in this case the name of the person to whom the score is attributed) or the index of the person. Take Rajesh for instance. As you can see here, you can retrieve his score by either using his name or the index '3', since this structure is zero-indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(diagnosticScoreAssignmentsWithCurve['Rajesh'])\n",
    "print(diagnosticScoreAssignmentsWithCurve[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also important to note that in ```Series```, you can retrieve data in the same way you can with ```ndarray```s. In fact, you can even use the string identifiers rather than numeric indices; however, unlike using numeric indices, the last value is included. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(diagnosticScoreAssignmentsWithCurve[\"Alice\":\"Rajesh\"]) #Rajesh's score is included because we are using the identifier, not the numeric index\n",
    "print(\"\\n\")\n",
    "print(diagnosticScoreAssignmentsWithCurve[1:4]) #Rajesh's score is excluded because we are using numeric indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ```DataFrame``` is essentially a table that consists of ```Series```. When multiple ```Series``` have the same indices, they can be combined into a table. In order to do this, we need to create a dictionary, which is similar to a Map construct in Java if you've used that before. It's best to see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoreDictionary = {\"Without Curve\" : diagnosticScoreAssignments, \"With Curve\" : diagnosticScoreAssignmentsWithCurve}\n",
    "scores = pd.DataFrame(scoreDictionary)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of a ```DataFrame``` is essentially a dictionary (or map, if you prefer to think of it like that) of ```Series```, so if we want to retrieve a specific value, we first enter the ```Series``` we want, then we enter the specific element identifier within that series. For example, let's say we wanted to know Katie's uncurved score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(scores[\"Without Curve\"][\"Katie\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory CSV Manipulation Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our first Wednesday Workshop, we asked you to create a folder on your desktop called \"AIClub,\" which is where your Jupyter notebooks should be placed. Please download [this iris csv file](https://drive.google.com/file/d/1xk2ZBOO0j7dI-bhOg5AQ0nBmHjFXz970/view?usp=sharing) and place it in your AIClub folder. Open it with a plain text editor (TextEdit on Mac, Notepad on Windows) to get an idea of its structure. This is the type of structure you'll see when manipulating datasets in machine learning. This particular dataset documents characteristics of types of flowers and is almost the \"hello, world\" of the machine learning world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV files are comma-delimited data-storage files. The pandas library conveniently has functionality that allows us to read data from CSVs directly into ```DataFrames```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"iris.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, pandas makes it easy for us to read CSV data! As long as it's formatted correctly, we can convert it directly to a ```DataFrame```. This type of functionality is why many people prefer Python for data analysis and machine learning projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to CSV files is pretty much as easy as it is to read them. Let's use our diagnostic scores example from earlier. What if I wanted to write the data to a CSV file? Well, it's a very simple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores.to_csv(\"scores.csv\") #Will place output CSV in AIClub folder (or wherever your notebook is located)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and make sure that you can now see a ```scores.csv``` file in your AIClub folder. Open it with TextEdit/Notepad to check it out!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
